# Backend - Financial AI Query System

This is the backend for a financial AI query system that leverages **FastAPI**, **Chroma** (a vector database), and **LLama Index** (a retrieval-augmented generation, RAG framework). The system allows users to query financial data and receive answers generated by a powerful language model (LLM) using the **Ollama** model.

## Features

- **FastAPI Server**: The backend is powered by FastAPI, providing a fast and modern web framework to handle API requests.
- **Chroma Vector Database**: Uses Chroma as a vector store to store and retrieve embeddings for efficient search and querying.
- **Embedding Models**: Uses a HuggingFace embedding model (`BAAI/bge-base-en-v1.5`) to convert text into embeddings that are stored in the Chroma vector database.
- **Query Engine**: Implements a query engine using the **Ollama** language model to generate responses based on user input.
- **CORS Support**: The backend includes CORS middleware to allow cross-origin requests, enabling frontend interaction.

## API Endpoints

### POST `/query`
This endpoint allows the user to send a query, and the backend will return a generated answer using the language model.

**Request Body:**

```json
{
  "question": "What is the full form of ATO?"
}
